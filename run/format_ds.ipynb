{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "project_name = \"PaddleSeg\"\n",
    "os.chdir(os.path.join(os.getcwd().split(project_name, 1)[0], project_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = os.path.join('Z:', 'datasets', 'cracks', 'Updated_Dataset', 'Final_Dataset')\n",
    "\n",
    "for prefix in ['train', 'test']:\n",
    "  with open(os.path.join(dir_path, f'{prefix}_main.txt'), 'w', encoding='utf-8') as f_main:\n",
    "    with open(os.path.join(dir_path, f'{prefix}.txt'), 'r', encoding='utf-8') as f:\n",
    "      for i, l in enumerate(f.readlines()):\n",
    "        name = l.strip()\n",
    "        image_name = os.path.join('Images', name)\n",
    "        label_name = os.path.join('Masks', name)\n",
    "        image_exists = os.path.exists(os.path.join(dir_path, image_name))\n",
    "        label_exists = os.path.exists(os.path.join(dir_path, label_name))\n",
    "        if image_exists and label_exists:\n",
    "          f_main.write(f\"{image_name} {label_name}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = 'Z:\\datasets\\cracks\\kzm\\paddle'\n",
    "with open(os.path.join(base_dir, 'test.txt'), 'w', encoding='utf-8') as ftest:\n",
    "  with open(os.path.join(base_dir, 'train.txt'), 'w', encoding='utf-8') as ftrain:\n",
    "    for i, fname in enumerate(os.listdir(os.path.join(base_dir, 'images'))):\n",
    "      fname = fname.split('.')[0]\n",
    "\n",
    "      image_name = [a for a in os.listdir(os.path.join(base_dir, 'images')) if a.startswith(fname)][0]\n",
    "      label_name = [a for a in os.listdir(os.path.join(base_dir, 'annotations')) if a.startswith(fname)][0]\n",
    "      image_path = os.path.join(base_dir, image_name)\n",
    "      label_path = os.path.join(base_dir, label_name)\n",
    "      output = f'{image_path} {label_path}\\n'\n",
    "      if i > 2:\n",
    "        ftrain.write(output)\n",
    "      else:\n",
    "        ftest.write(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = os.path.join('Z:', 'datasets', 'cracks', 'Updated_Dataset', 'Final_Dataset')\n",
    "with open(os.path.join(dir_path, 'train_second.txt'), 'w', encoding='utf-8') as f2:\n",
    "  with open(os.path.join(dir_path, 'train_main.txt'), 'r', encoding='utf-8') as f:\n",
    "      lines = f.readlines()\n",
    "      print(len(lines))\n",
    "      for l in lines:\n",
    "          # Splitting the line and stripping the newline character\n",
    "          img_path, mask_path = [s.strip() for s in l.split(' ')]\n",
    "          if os.path.exists(os.path.join(dir_path, img_path)) and os.path.exists(os.path.join(dir_path, mask_path)):\n",
    "              output = f'{mask_path} {img_path}\\n'\n",
    "              f2.write(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def count_unique_pixels(image_path):\n",
    "    # Load the image\n",
    "    image = Image.open(image_path)\n",
    "\n",
    "    # Convert to grayscale if it's a color image\n",
    "    if image.mode != 'L':\n",
    "        image = image.convert('L')\n",
    "\n",
    "    # Convert to NumPy array for efficient computation\n",
    "    image_array = np.array(image)\n",
    "\n",
    "    # Find unique pixel values and their counts\n",
    "    unique_pixels, counts = np.unique(image_array, return_counts=True)\n",
    "\n",
    "    # Creating a dictionary for pixel values and their counts\n",
    "    pixel_count = dict(zip(unique_pixels, counts))\n",
    "\n",
    "    return pixel_count\n",
    "\n",
    "# Example usage\n",
    "image_path = os.path.join(f'P:\\PaddleSeg\\outputs\\hrsegnetb48\\\\result\\\\2\\pseudo_color_prediction\\\\2_5.png')\n",
    "# image_path = os.path.join('Z:\\datasets\\cracks\\kzm\\masks', '0_9.png')\n",
    "unique_pixel_count = count_unique_pixels(image_path)\n",
    "print(unique_pixel_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = os.path.join('Z:', 'datasets', 'cracks', 'Updated_Dataset', 'Final_Dataset')\n",
    "\n",
    "valid_images = []\n",
    "\n",
    "for fname in os.listdir(os.path.join(dir_path, 'Images')):\n",
    "  if os.path.exists(os.path.join(dir_path, 'FIXED', fname)):\n",
    "    valid_images.append(fname)\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "def group_strings_by_prefix(strings):\n",
    "    prefix_groups = defaultdict(list)\n",
    "    \n",
    "    # Iterate over each string\n",
    "    for string in strings:\n",
    "        # Use the first three characters as the key\n",
    "        prefix = string[:3]\n",
    "        # Append the string to the corresponding group\n",
    "        prefix_groups[prefix].append(string)\n",
    "    \n",
    "    # Convert defaultdict to a regular dictionary for output\n",
    "    return dict(prefix_groups)\n",
    "\n",
    "\n",
    "dicted = group_strings_by_prefix(valid_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def split_dataset(strings, train_ratio, val_ratio):\n",
    "    # Calculate total number of items based on the ratio\n",
    "    total_ratio = train_ratio + val_ratio\n",
    "    train_count = len(strings) * train_ratio // total_ratio\n",
    "\n",
    "    # Shuffle the list in-place to ensure random distribution\n",
    "    random.shuffle(strings)\n",
    "\n",
    "    # Split the list\n",
    "    train_subset = strings[:train_count]\n",
    "    val_subset = strings[train_count:]\n",
    "\n",
    "    return train_subset, val_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Ris', 'non', 'GAP', 'CRA'])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dicted.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ris 2736 2188 548 2736\n",
      "GAP 383 306 77 383\n",
      "CRA 1785 1428 357 1785\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(dir_path, 'train_main.txt'), 'w', encoding='utf-8') as train_f:\n",
    "  with open(os.path.join(dir_path, 'val_main.txt'), 'w', encoding='utf-8') as val_f:\n",
    "    for key, img_names in dicted.items():\n",
    "      if key == 'non':\n",
    "        continue\n",
    "      train_ds, val_ds = split_dataset(img_names, 8, 2)\n",
    "      print(key, len(img_names), len(train_ds), len(val_ds), sum([len(train_ds), len(val_ds)]))\n",
    "      for fname in train_ds:\n",
    "        image_path = os.path.join('Images', fname)\n",
    "        mask_path = os.path.join('FIXED', fname)\n",
    "        train_f.write(f'{image_path} {mask_path}\\n')\n",
    "      for fname in val_ds:\n",
    "        image_path = os.path.join('Images', fname)\n",
    "        mask_path = os.path.join('FIXED', fname)\n",
    "        val_f.write(f'{image_path} {mask_path}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(dir_path, 'train_main.txt'), 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "    for l in lines:\n",
    "        # Splitting the line and stripping the newline character\n",
    "        img_path, mask_path = [s.strip() for s in l.split(' ')]\n",
    "        if os.path.exists(os.path.join(dir_path, img_path)) and os.path.exists(os.path.join(dir_path, mask_path)):\n",
    "            output = f'{mask_path} {img_path}\\n'\n",
    "            f2.write(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "982\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "dir_path = os.path.join('Z:', 'datasets', 'cracks', 'Updated_Dataset', 'Final_Dataset')\n",
    "\n",
    "def binarize_image(file_name, threshold=127):\n",
    "    img_path = os.path.join(dir_path, 'Masks', file_name)\n",
    "    image = Image.open(img_path)\n",
    "    image_array = np.array(image)\n",
    "    binarized_array = np.where(image_array > threshold, 255, 0)\n",
    "    binarized_image = Image.fromarray(binarized_array.astype(np.uint8))\n",
    "    binarized_image.save(os.path.join(dir_path, 'Fixed', file_name))\n",
    "\n",
    "with open(os.path.join(dir_path, 'val_main.txt'), 'r', encoding='utf-8') as f:\n",
    "  lines = f.readlines()\n",
    "  print(len(lines))\n",
    "  for l in lines:\n",
    "    # Splitting the line and stripping the newline character\n",
    "    img_path, mask_path = [s.strip() for s in l.split(' ')]\n",
    "    fi, sec = img_path.split(os.path.sep)\n",
    "    img_full_path = os.path.join(dir_path, img_path)\n",
    "    mask_full_path = os.path.join(dir_path, 'Masks', sec)\n",
    "    # print(f'[{img_full_path}]')\n",
    "    # print(f'[{mask_full_path}]')\n",
    "    if os.path.exists(img_full_path) and os.path.exists(mask_full_path):\n",
    "      _, file_name = mask_path.split(os.sep)\n",
    "      # print(mask_path)\n",
    "      binarize_image(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_colors(file_name):\n",
    "    img_path = os.path.join(dir_path, 'Masks', file_name)\n",
    "    image = Image.open(img_path)\n",
    "\n",
    "    # Ensure the image is in RGBA mode\n",
    "    if image.mode != 'RGBA':\n",
    "        image = image.convert('RGBA')\n",
    "    \n",
    "    # Convert image to numpy array\n",
    "    data = np.array(image)\n",
    "\n",
    "    # Create a mask for non-black (all non-zero) pixels - these will become red\n",
    "    non_black_pixels_mask = (data[:, :, :3] != 0).any(-1)\n",
    "\n",
    "    # Create a mask for black (all zero) pixels - these will become green\n",
    "    black_pixels_mask = (data[:, :, :3] == 0).all(-1)\n",
    "\n",
    "    # Change non-black (white and other colors) to red\n",
    "    data[black_pixels_mask] = [255, 0, 0, 255]  # RGBA for red\n",
    "\n",
    "    # Change black to green\n",
    "    data[non_black_pixels_mask] = [0, 255, 0, 255]  # RGBA for green\n",
    "\n",
    "    # Convert the numpy array back to an image\n",
    "    new_image = Image.fromarray(data)\n",
    "\n",
    "    # Save the new image\n",
    "    new_image.save(os.path.join(dir_path, 'Fixed2', file_name))\n",
    "\n",
    "with open(os.path.join(dir_path, 'val_main.txt'), 'r', encoding='utf-8') as f:\n",
    "  lines = f.readlines()\n",
    "  for l in lines:\n",
    "    # Splitting the line and stripping the newline character\n",
    "    img_path, mask_path = [s.strip() for s in l.split(' ')]\n",
    "    mask_full_path = os.path.join(dir_path, mask_path)\n",
    "    img_full_path = os.path.join(dir_path, img_path)\n",
    "    if os.path.exists(img_full_path) and os.path.exists(mask_full_path):\n",
    "      _, file_name = mask_path.split(os.sep)\n",
    "      # print(mask_path)\n",
    "      change_colors(file_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
